{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('TF': conda)",
   "display_name": "Python 3.7.9 64-bit ('TF': conda)",
   "metadata": {
    "interpreter": {
     "hash": "9867c6a6cb13a5eb606d1ad40b7aaabec0f2060805d3bcff845dff23b269a916"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Dictionary(train_dir):\n",
    "    emails = [os.path.join(train_dir,f) for f in os.listdir(train_dir)]\n",
    "    all_words = []\n",
    "    for mail in emails:\n",
    "        with open(mail) as m:\n",
    "            for i,line in enumerate(m):\n",
    "                if i == 2:  #Body of email is only 3rd line of text file\n",
    "                    words = line.split()\n",
    "                    all_words += words\n",
    "    dictionary = Counter(all_words)\n",
    "    dictionary_temp = Counter(all_words)\n",
    "\n",
    "    # Paste code for non-word removal here(code snippet is given below)\n",
    "    list_to_remove = dictionary_temp.keys()\n",
    "    for item in list_to_remove:\n",
    "        if item.isalpha() == False:    #Determine whether it is punctuation\n",
    "            del dictionary[item]\n",
    "        elif len(item) == 1:           #\n",
    "            del dictionary[item]\n",
    "    dictionary = dictionary.most_common(3000)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(root_dir,dictionary):\n",
    "    emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n",
    "    all_words = []\n",
    "    features_matrix = np.zeros((len(emails),3000))\n",
    "    docID = 0\n",
    "    for mail in emails:\n",
    "        with open(mail) as m:\n",
    "            for i,line in enumerate(m):\n",
    "                if i == 2:\n",
    "                    words = line.split()\n",
    "                    for word in words:\n",
    "                        wordID = 0\n",
    "                        for i,d in enumerate(dictionary):\n",
    "                            if d[0] == word:\n",
    "                                wordID = i\n",
    "                                features_matrix[docID,wordID] = words.count(word)\n",
    "        docID = docID + 1\n",
    "    return features_matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "', 16), ('beyond', 16), ('prosodic', 16), ('complement', 16), ('shall', 16), ('verbal', 16), ('representative', 16), ('round', 16), ('challenge', 16), ('aware', 16), ('monitor', 16), ('latin', 16), ('bob', 16), ('responsibility', 16), ('reasonable', 16), ('literally', 16), ('jan', 16), ('ren', 16), ('character', 16), ('eventually', 16), ('light', 16), ('approximately', 16), ('parameter', 16), ('preposition', 16), ('ease', 16), ('examine', 16), ('attitude', 16), ('equivalent', 16), ('diurnal', 16), ('humanity', 16), ('pencil', 16), ('phillip', 16), ('tend', 16), ('italy', 16), ('possibly', 16), ('scandinavian', 16), ('reap', 16), ('christmas', 16), ('village', 16), ('inside', 16), ('appeal', 16), ('successfully', 16), ('statistics', 16), ('wall', 16), ('coupon', 16), ('browser', 16), ('smtp', 16), ('specialize', 16), ('extraordinary', 16), ('vision', 16), ('gay', 16), ('liar', 16), ('boss', 16), ('racer', 16), ('snail', 16), ('tips', 16), ('reg', 16), ('golden', 16), ('secrets', 16), ('thousands', 16), ('vga', 16), ('kit', 16), ('broken', 16), ('listserv', 15), ('highlight', 15), ('expand', 15), ('breakfast', 15), ('door', 15), ('cycle', 15), ('whom', 15), ('characteristic', 15), ('da', 15), ('capture', 15), ('gb', 15), ('alexis', 15), ('stand', 15), ('lanse', 15), ('summarize', 15), ('encode', 15), ('ethnic', 15), ('alan', 15), ('stick', 15), ('fail', 15), ('maria', 15), ('applicant', 15), ('identify', 15), ('roger', 15), ('analytic', 15), ('airport', 15), ('primarily', 15), ('france', 15), ('tag', 15), ('manufacturer', 15), ('assist', 15), ('innovative', 15), ('favor', 15), ('curious', 15), ('gift', 15), ('harvard', 15), ('england', 15), ('asian', 15), ('moreover', 15), ('resident', 15), ('universitaet', 15), ('textbook', 15), ('japan', 15), ('strike', 15), ('assessment', 15), ('surface', 15), ('productive', 15), ('lawyer', 15), ('subscribe', 15), ('contents', 15), ('esl', 15), ('exclude', 15), ('data', 15), ('trick', 15), ('flow', 15), ('oh', 15), ('dozen', 15), ('leed', 15), ('pacific', 15), ('believer', 15), ('gather', 15), ('fight', 15), ('iowa', 15), ('photo', 15), ('extend', 15), ('groningen', 15), ('jeff', 15), ('death', 15), ('military', 15), ('mix', 15), ('significant', 15), ('vehicle', 15), ('patient', 15), ('ours', 15), ('affair', 15), ('energy', 15), ('beat', 15), ('linux', 15), ('informative', 15), ('flaw', 15), ('clothe', 15), ('intrusion', 15), ('biggest', 15), ('jasmin', 15), ('tracus', 15), ('porn', 15), ('qty', 15), ('earnings', 15), ('retirement', 15), ('utilize', 15), ('amateur', 15), ('anytime', 15), ('unsolicit', 15), ('regardless', 15), ('ofs', 15), ('raleigh', 15), ('stamped', 15), ('scholar', 14), ('reflect', 14), ('morn', 14), ('nearly', 14), ('anthropology', 14), ('vita', 14), ('durham', 14), ('hence', 14), ('intuition', 14), ('tamu', 14), ('familiar', 14), ('transcription', 14), ('thoma', 14), ('older', 14), ('lsa', 14), ('normally', 14), ('confuse', 14), ('violation', 14), ('latter', 14), ('ltd', 14), ('explore', 14), ('syllable', 14), ('solve', 14), ('perception', 14), ('christopher', 14), ('phd', 14), ('display', 14), ('interface', 14), ('notification', 14), ('reaction', 14), ('water', 14), ('authority', 14), ('methodology', 14), ('careful', 14), ('italian', 14), ('inflection', 14), ('translate', 14), ('solid', 14), ('component', 14), ('preferably', 14), ('merge', 14), ('evaluate', 14), ('balance', 14), ('apologize', 14), ('implication', 14), ('tutorial', 14), ('compute', 14), ('calculate', 14), ('persistent', 14), ('ball', 14), ('failure', 14), ('glad', 14), ('husband', 14), ('barbara', 14), ('bp', 14), ('span', 14), ('entry', 14), ('upset', 14), ('confidence', 14), ('counter', 14), ('push', 14), ('intonation', 14), ('brazilian', 14), ('reward', 14), ('presumably', 14), ('binary', 14), ('white', 14), ('repeat', 14), ('pamelum', 14), ('deep', 14), ('unmark', 14), ('steal', 14), ('gesture', 14), ('revenue', 14), ('frame', 14), ('winner', 14), ('prospective', 14), ('turkic', 14), ('independence', 14), ('survive', 14), ('hawaius', 14), ('brian', 14), ('barcelona', 14), ('pronominal', 14), ('effectively', 14), ('straight', 14), ('setup', 14), ('bounce', 14), ('ads', 14), ('annabel', 14), ('richer', 14), ('toy', 14), ('bad', 14), ('coreference', 14), ('percentage', 14), ('mci', 14), ('trash', 14), ('driver', 14), ('bull', 14), ('teen', 14), ('criminal', 14), ('privacy', 14), ('residual', 14), ('returns', 14), ('futuresignal', 14), ('jump', 14), ('banner', 14), ('advertising', 14), ('inflation', 14), ('casino', 14), ('logical', 13), ('remind', 13), ('writer', 13), ('tuesday', 13), ('aim', 13), ('industrial', 13), ('administrative', 13), ('surround', 13), ('specify', 13), ('salt', 13), ('fix', 13), ('el', 13), ('nobody', 13), ('psychology', 13), ('formation', 13), ('accent', 13), ('nj', 13), ('none', 13), ('adjective', 13), ('cogscus', 13), ('scientist', 13), ('uc', 13), ('matthew', 13), ('define', 13), ('affect', 13), ('humorous', 13), ('conversational', 13), ('combination', 13), ('faculty', 13), ('children', 13), ('motivate', 13), ('iii', 13), ('mostly', 13), ('classical', 13), ('expertise', 13), ('usc', 13), ('station', 13), ('union', 13), ('heart', 13), ('prospect', 13), ('notify', 13), ('merely', 13), ('personality', 13), ('constitute', 13), ('sing', 13), ('active', 13), ('coin', 13), ('equipment', 13), ('cte', 13), ('parse', 13), ('pronounce', 13), ('construct', 13), ('dialogue', 13), ('specialist', 13), ('daniel', 13), ('retain', 13), ('polish', 13), ('nation', 13), ('household', 13), ('incorporate', 13), ('distinguish', 13), ('anyway', 13), ('trouble', 13), ('hebrew', 13), ('imperative', 13), ('band', 13), ('lie', 13), ('posting', 13), ('cross', 13), ('attract', 13), ('amherst', 13), ('map', 13), ('spot', 13), ('crime', 13), ('intercourse', 13), ('diskette', 13), ('mathematical', 13), ('complaint', 13), ('resort', 13), ('keyboard', 13), ('ne', 13), ('truth', 13), ('rental', 13), ('bond', 13), ('pain', 13), ('du', 13), ('liddell', 13), ('seriously', 13), ('comprehensive', 13), ('motor', 13), ('postcard', 13), ('mil', 13), ('moo', 13), ('homepage', 13), ('illegal', 13), ('smart', 13), ('ratio', 13), ('tire', 13), ('confidential', 13), ('msn', 13), ('juno', 13), ('birth', 13), ('affordable', 13), ('finance', 13), ('tout', 13), ('flamer', 13), ('biz', 13), ('pic', 13), ('recipe', 13), ('skeptical', 13), ('pipeline', 13), ('spouse', 13), ('selle', 13), ('reprint', 13), ('removal', 13), ('guild', 13), ('fetish', 13), ('desirous', 13), ('totals', 13), ('sean', 13), ('mclaughlin', 13), ('lawful', 13), ('astonishment', 13), ('cram', 13), ('fairchild', 13), ('spokane', 13), ('comfort', 13), ('svminus', 13), ('false', 12), ('critical', 12), ('reception', 12), ('entitle', 12), ('compete', 12), ('busy', 12), ('xerox', 12), ('experiment', 12), ('un', 12), ('elizabeth', 12), ('cuny', 12), ('princeton', 12), ('taiwan', 12), ('mb', 12), ('dick', 12), ('mountain', 12), ('tongue', 12), ('restrict', 12), ('operator', 12), ('bilingual', 12), ('output', 12), ('differ', 12), ('genre', 12), ('dislocation', 12), ('fourth', 12), ('lecture', 12), ('employer', 12), ('minority', 12), ('metro', 12), ('exceed', 12), ('genuine', 12), ('infinitive', 12), ('larry', 12), ('rock', 12), ('pop', 12), ('spread', 12), ('conduct', 12), ('scope', 12), ('danish', 12), ('memory', 12), ('slavic', 12), ('hop', 12), ('von', 12), ('adopt', 12), ('twelve', 12), ('recommendation', 12), ('strange', 12), ('administration', 12), ('thereafter', 12), ('rutger', 12), ('fuer', 12), ('singapore', 12), ('furthermore', 12), ('argue', 12), ('workplace', 12), ('slow', 12), ('grounds', 12), ('red', 12), ('purely', 12), ('utrecht', 12), ('arm', 12), ('bulgarian', 12), ('neither', 12), ('celebrate', 12), ('confident', 12), ('entirely', 12), ('massachusett', 12), ('tomorrow', 12), ('innateness', 12), ('found', 12), ('region', 12), ('proud', 12), ('reproduce', 12), ('honor', 12), ('county', 12), ('anna', 12), ('editorial', 12), ('flame', 12), ('lowland', 12), ('atlantic', 12), ('trend', 12), ('te', 12), ('sue', 12), ('transmission', 12), ('victim', 12), ('wonderful', 12), ('compress', 12), ('tr', 12), ('partnership', 12), ('mx', 12), ('doorstep', 12), ('pack', 12), ('path', 12), ('yuen', 12), ('diachronic', 12), ('log', 12), ('ga', 12), ('ourselve', 12), ('pheromone', 12), ('allen', 12), ('wave', 12), ('jun', 12), ('firm', 12), ('bit', 12), ('commerce', 12), ('amlap', 12), ('required', 12), ('birthday', 12), ('fastest', 12), ('brooklyn', 12), ('legally', 12), ('paid', 12), ('entertainment', 12), ('stream', 12), ('refinance', 12), ('vendor', 12), ('cearth', 12), ('sericel', 12), ('cum', 12), ('embark', 12), ('prepared', 12), ('benefits', 12), ('grumble', 12), ('spout', 12), ('merciless', 12), ('rat', 12), ('esq', 12), ('rockland', 12), ('rewrite', 12), ('blast', 12), ('stun', 12), ('cancun', 12), ('investnet', 12), ('excerpt', 12), ('instantly', 12), ('entity', 11), ('dinner', 11), ('arrange', 11), ('venice', 11), ('cheap', 11), ('rug', 11), ('frus', 11), ('ken', 11), ('beesley', 11), ('montreal', 11), ('salary', 11), ('judgement', 11), ('violate', 11), ('thought', 11), ('norm', 11), ('communicative', 11), ('facility', 11), ('proceed', 11), ('institutional', 11), ('typically', 11), ('silver', 11), ('former', 11), ('george', 11), ('clue', 11), ('mechanism', 11), ('budget', 11), ('alabama', 11), ('strength', 11), ('michigan', 11), ('rice', 11), ('experimental', 11), ('twenty', 11), ('facilitate', 11), ('worry', 11), ('arnold', 11), ('yield', 11), ('lexicon', 11), ('intention', 11), ('feed', 11), ('speakers', 11), ('systemic', 11), ('economic', 11), ('hbe', 11), ('mill', 11), ('rd', 11), ('ucla', 11), ('women', 11), ('diego', 11), ('xiv', 11), ('highway', 11), ('gl', 11), ('arise', 11), ('sum', 11), ('mystery', 11), ('hardware', 11), ('sgml', 11), ('afraid', 11), ('god', 11), ('central', 11), ('friendly', 11), ('father', 11), ('tokyo', 11), ('anderson', 11), ('accuracy', 11), ('snow', 11), ('bother', 11), ('vernacular', 11), ('abuse', 11), ('extension', 11), ('reading', 11), ('hearer', 11), ('finnish', 11), ('norwegian', 11), ('anu', 11), ('spell', 11), ('comrie', 11), ('migration', 11), ('diversity', 11), ('greenberg', 11), ('classification', 11), ('namely', 11), ('sil', 11), ('australian', 11), ('evolution', 11), ('documentation', 11), ('unix', 11), ('manager', 11), ('vote', 11), ('pb', 11), ('prefix', 11), ('excuse', 11), ('belong', 11), ('diana', 11), ('catch', 11), ('originally', 11), ('soviet', 11), ('mother', 11), ('ist', 11), ('maximize', 11), ('dead', 11), ('ruth', 11), ('caucasian', 11), ('caucasus', 11), ('armey', 11), ('mouse', 11), ('complain', 11), ('insertion', 11), ('bargain', 11), ('deduct', 11), ('inclusion', 11), ('carl', 11), ('repair', 11), ('completion', 11), ('beg', 11), ('fulfill', 11), ('intensification', 11), ('via', 11), ('massive', 11), ('blow', 11), ('twice', 11), ('linguistlist', 11), ('zero', 11), ('ld', 11), ('obey', 11), ('suit', 11), ('ferraz', 11), ('preview', 11), ('barsky', 11), ('tommy', 11), ('patent', 11), ('spare', 11), ('fraction', 11), ('released', 11), ('clearance', 11), ('launch', 11), ('divorce', 11), ('checks', 11), ('airline', 11), ('fabulous', 11), ('dental', 11), ('vbanaqeanvsuprqpnpphx', 11), ('llc', 11), ('promptly', 11), ('goods', 11), ('awesome', 11), ('isdn', 11), ('investigative', 11), ('compaq', 11), ('rntk', 11), ('belgium', 10), ('keynote', 10), ('tea', 10), ('restaurant', 10), ('pari', 10), ('jim', 10), ('convention', 10), ('micro', 10), ('absolute', 10), ('apr', 10), ('scholarly', 10), ('santa', 10), ('poster', 10), ('negotiate', 10), ('approval', 10), ('cf', 10), ('glasgow', 10), ('eugene', 10), ('celtic', 10), ('church', 10), ('foundation', 10), ('adverb', 10), ('bar', 10), ('anthony', 10), ('typology', 10), ('precede', 10), ('proposal', 10), ('lien', 10), ('bed', 10), ('appointment', 10), ('referee', 10), ('tesl', 10), ('capable', 10), ('wccfl', 10), ('jose', 10), ('interactional', 10), ('virginium', 10), ('route', 10), ('corner', 10), ('walter', 10), ('interpret', 10), ('tour', 10), ('heavy', 10), ('input', 10), ('assistance', 10), ('fashion', 10), ('norway', 10), ('lingua', 10), ('concordance', 10), ('conflict', 10), ('commonly', 10), ('contrastive', 10), ('extreme', 10), ('rare', 10), ('secondary', 10), ('apple', 10), ('importance', 10), ('obvious', 10), ('positive', 10), ('expert', 10), ('innate', 10), ('recognition', 10), ('claire', 10), ('examination', 10), ('mall', 10), ('treasury', 10), ('deny', 10), ('max', 10), ('frequently', 10), ('clip', 10), ('steven', 10), ('wherea', 10), ('subjunctive', 10), ('minus', 10), ('similarity', 10), ('controversial', 10), ('stable', 10), ('citizen', 10), ('approve', 10), ('recording', 10), ('comprehension', 10), ('trail', 10), ('dislike', 10), ('circumstance', 10), ('encounter', 10), ('complexity', 10), ('donald', 10), ('morpheme', 10), ('literacy', 10), ('muncie', 10), ('th', 10), ('athen', 10), ('ancient', 10), ('switch', 10), ('geoffrey', 10), ('congress', 10), ('import', 10), ('sle', 10), ('johanna', 10), ('irit', 10), ('icc', 10), ('integrate', 10), ('administrator', 10), ('defend', 10), ('explicit', 10), ('season', 10), ('defense', 10), ('prime', 10), ('sterl', 10), ('sriharus', 10), ('shame', 10), ('shares', 10), ('horse', 10), ('homosexual', 10), ('contest', 10), ('ted', 10), ('corporate', 10), ('heterosexual', 10), ('fieldwork', 10), ('pull', 10), ('ea', 10), ('assure', 10), ('revolution', 10), ('educational', 10), ('hfl', 10), ('cure', 10), ('adults', 10), ('consistently', 10), ('buck', 10), ('burn', 10), ('multilevel', 10), ('seller', 10), ('living', 10), ('savings', 10), ('broker', 10), ('anon', 10), ('amex', 10), ('imagination', 10), ('yahoo', 10), ('lesbian', 10), ('countless', 10), ('mega', 10), ('recieve', 10), ('sleuth', 10), ('bundle', 10), ('kitchen', 10), ('proven', 10), ('cancel', 10), ('messages', 10), ('amd', 10), ('bondage', 10), ('undoubtedly', 10), ('awhile', 10), ('complimentary', 10), ('math', 10), ('premium', 10), ('goodness', 10), ('spammer', 10), ('originate', 10), ('descrambler', 10), ('capacitor', 10), ('expose', 10), ('unsubscribe', 10), ('fantasy', 10), ('eepp', 10), ('robbie', 10), ('telecom', 10), ('detective', 10), ('attribute', 9), ('pala', 9), ('pub', 9), ('brussel', 9), ('territory', 9), ('lake', 9), ('ce', 9), ('romance', 9), ('phonetician', 9), ('cornell', 9), ('incorrect', 9), ('ff', 9), ('universite', 9), ('intensive', 9), ('integration', 9), ('afterward', 9), ('nathan', 9), ('hill', 9), ('reflection', 9), ('broad', 9), ('stephen', 9), ('saarbruecken', 9), ('scientific', 9), ('board', 9), ('insight', 9), ('eric', 9), ('nominal', 9), ('quantification', 9), ('nottingham', 9), ('spatial', 9), ('desirable', 9), ('senior', 9), ('religion', 9), ('affirmative', 9), ('interdisciplinary', 9), ('visual', 9), ('predication', 9), ('frederick', 9), ('hamilton', 9), ('inn', 9), ('regularly', 9), ('feb', 9), ('widely', 9), ('pursue', 9), ('string', 9), ('scott', 9), ('chri', 9), ('fool', 9), ('necessarily', 9), ('generator', 9), ('division', 9), ('preserve', 9), ('religious', 9), ('disappear', 9), ('yale', 9), ('frequent', 9), ('river', 9), ('catherine', 9), ('honestly', 9), ('hire', 9), ('las', 9), ('manner', 9), ('statistical', 9), ('manchester', 9), ('necessity', 9), ('derivational', 9), ('hint', 9), ('criterion', 9), ('alex', 9), ('judge', 9), ('unlikely', 9), ('preliminary', 9), ('hpsg', 9), ('flexibility', 9), ('adoption', 9), ('procedure', 9), ('differently', 9), ('hindus', 9), ('wayne', 9), ('bag', 9), ('poison', 9), ('ge', 9), ('branch', 9), ('roughly', 9), ('bruce', 9), ('neal', 9), ('aaa', 9), ('land', 9), ('apart', 9), ('cognate', 9), ('china', 9), ('airfare', 9), ('signal', 9), ('kevin', 9), ('watt', 9), ('iulc', 9), ('duplication', 9), ('asymmetry', 9), ('behind', 9), ('scenario', 9), ('partial', 9), ('ronald', 9), ('joseph', 9), ('concentrate', 9), ('clock', 9), ('greece', 9), ('fist', 9), ('alphabet', 9), ('ein', 9), ('creat', 9), ('panel', 9), ('dure', 9), ('strict', 9), ('representational', 9), ('minimalist', 9), ('toulouse', 9), ('andrea', 9), ('instructional', 9), ('presenter', 9), ('neighbor', 9), ('comparable', 9), ('orthography', 9), ('unemployment', 9), ('regional', 9), ('wealthy', 9), ('anti', 9), ('clinical', 9), ('rohinus', 9), ('caption', 9), ('tab', 9), ('glide', 9), ('houston', 9), ('privately', 9), ('worst', 9), ('tucson', 9), ('kanzus', 9), ('comprehend', 9), ('pardon', 9), ('keller', 9), ('collin', 9), ('oversight', 9), ('accomplish', 9), ('uci', 9), ('thompson', 9), ('webster', 9), ('encouragement', 9), ('outstand', 9), ('bog', 9), ('newest', 9), ('pkzip', 9), ('explode', 9), ('stampe', 9), ('romanization', 9), ('francisco', 9), ('endless', 9), ('valkhoff', 9), ('continual', 9), ('shoriya', 9), ('quantity', 9), ('talmy', 9), ('approx', 9), ('removed', 9), ('fold', 9), ('tonya', 9), ('lord', 9), ('exp', 9), ('referral', 9), ('compliance', 9), ('permanently', 9), ('hud', 9), ('consumer', 9), ('dupe', 9), ('robbery', 9), ('authenticate', 9), ('mime', 9), ('charset', 9), ('emailer', 9), ('bottle', 9), ('friends', 9), ('explosive', 9), ('sleep', 9), ('fortunately', 9), ('wilburn', 9), ('filled', 9), ('continent', 9), ('overflow', 9), ('bin', 9), ('someday', 9), ('dare', 9), ('respectfully', 9), ('pentium', 9), ('corp', 9), ('desktop', 9), ('deliverable', 9), ('included', 9), ('rousseau', 9), ('earning', 9), ('medieval', 8), ('bridge', 8), ('confirmation', 8), ('korean', 8), ('deeply', 8), ('patrick', 8), ('shortly', 8), ('asl', 8), ('aux', 8), ('premier', 8), ('concord', 8), ('kroch', 8), ('ellipsis', 8), ('connecticut', 8), ('folks', 8), ('que', 8), ('alouse', 8), ('seegmiller', 8), ('criticism', 8), ('classic', 8), ('satisfaction', 8), ('han', 8), ('transcr', 8), ('ecole', 8), ('sport', 8), ('perceive', 8), ('privilege', 8), ('geoff', 8), ('analogy', 8), ('grammarian', 8), ('descriptive', 8), ('bible', 8), ('microsoft', 8), ('floor', 8), ('predicate', 8), ('fairly', 8), ('intellectual', 8), ('newly', 8), ('extent', 8), ('suny', 8), ('mode', 8), ('blackwell', 8), ('mouth', 8), ('specialization', 8), ('goe', 8), ('anne', 8), ('dimension', 8), ('tim', 8), ('conjunction', 8), ('cognition', 8), ('developments', 8), ('weekend', 8), ('rise', 8), ('govern', 8), ('enhance', 8), ('tony', 8), ('exception', 8), ('fiction', 8), ('estimate', 8), ('ongo', 8), ('bee', 8), ('venture', 8), ('framework', 8), ('closely', 8), ('emerge', 8), ('optimality', 8), ('institut', 8), ('shareware', 8), ('numeral', 8), ('prepositional', 8), ('adjacent', 8), ('languages', 8), ('nlpeople', 8), ('aus', 8), ('academy', 8), ('printer', 8), ('valley', 8), ('nicola', 8), ('contemporary', 8), ('derivation', 8), ('reminder', 8), ('arbitrary', 8), ('eskimo', 8), ('sery', 8), ('grind', 8), ('brazil', 8), ('correction', 8), ('bailey', 8), ('escape', 8), ('subsequent', 8), ('bird', 8), ('shoot', 8), ('float', 8), ('lar', 8), ('lund', 8), ('conventional', 8), ('insult', 8), ('horn', 8), ('bernard', 8), ('millennium', 8), ('nostratic', 8), ('proto', 8), ('resemblance', 8), ('attendance', 8), ('hopefully', 8), ('made', 8), ('beth', 8), ('hausa', 8), ('yesterday', 8), ('symmetrical', 8), ('plug', 8), ('grateful', 8), ('measure', 8), ('mo', 8), ('conceptual', 8), ('inconvenience', 8), ('ix', 8), ('behavior', 8), ('shape', 8), ('electric', 8), ('export', 8), ('fear', 8), ('preparation', 8), ('kindly', 8), ('lodge', 8), ('freely', 8), ('reject', 8), ('divide', 8), ('capability', 8), ('pleasure', 8), ('simultaneously', 8), ('lui', 8), ('urbana', 8), ('guest', 8), ('adam', 8), ('learnability', 8), ('mellon', 8), ('vincent', 8), ('negotiation', 8), ('authentic', 8), ('assemble', 8), ('ensure', 8)]\n[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 1. 0. ... 0. 0. 0.]]\n[[ 1.  0.  0. ...  0.  0.  0.]\n [ 1.  1.  0. ...  0.  0.  0.]\n [ 1.  0.  0. ...  0.  0.  0.]\n ...\n [ 0.  0.  0. ...  0.  0.  0.]\n [ 0.  0.  0. ...  0.  0.  0.]\n [17.  2.  0. ...  0.  0.  0.]]\n"
    }
   ],
   "source": [
    "Path = \"train-mails\"\n",
    "dir = make_Dictionary(Path)\n",
    "# print('finish dir:\\n',dir)\n",
    "train_matrix = extract_features(Path,dir)\n",
    "print(train_matrix)\n",
    "\n",
    "Path_test = \"test-mails\"\n",
    "test_matrix = extract_features(Path_test,dir)\n",
    "print(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    train_data = []\n",
    "    Mean = {}\n",
    "    Std = {}\n",
    "    Prob = {}\n",
    "    def fit(self,x,y):\n",
    "        #divide x by x\n",
    "        DivideX = {}\n",
    "        for i in range(len(y)):\n",
    "            if (y[i] not in DivideX):\n",
    "                DivideX[y[i]]=[]\n",
    "                DivideX[y[i]].append(x[i])\n",
    "            else:\n",
    "                DivideX[y[i]] = np.vstack((DivideX[y[i]],x[i]))\n",
    "        self.train_data = DivideX\n",
    "        for key in DivideX:\n",
    "            self.Mean[key] = []\n",
    "            self.Std[key] = []\n",
    "            self.Prob[key] = []\n",
    "            for i in range(DivideX[key].shape[1]):\n",
    "                self.Mean[key].append(np.mean(DivideX[key][:,i]))\n",
    "                #Divide\n",
    "                c = 0\n",
    "                for j in DivideX[key][:,i]:\n",
    "                    if j >= self.Mean[key][i]:\n",
    "                        c += 1\n",
    "                num = len(DivideX[key][:,i])\n",
    "                self.Prob[key].append(c + 1/num + 1)\n",
    "                #\n",
    "                if np.std(DivideX[key][:,i]) == 0:\n",
    "                    self.Std[key].append(0.00001)\n",
    "                else:\n",
    "                    self.Std[key].append(np.std(DivideX[key][:,i]))\n",
    "        # print(self.Mean)\n",
    "    def probabilty(self,data,key):\n",
    "        prob = 1\n",
    "        # print(data)\n",
    "        for i in range(len(data)):\n",
    "            if self.Std[key][i] == 0:\n",
    "                if data[i] >= self.Mean[key][i]:\n",
    "                    print('!!!')\n",
    "                    prob *= self.Prob[key][i]\n",
    "                else:\n",
    "                    prob *= (1 - self.Prob[key][i])\n",
    "            else:\n",
    "                exp = math.exp(-(math.pow(data[i] - self.Mean[key][i],2)/(2*math.pow(self.Std[key][i],2))))\n",
    "                prob *= (1/(math.sqrt(2*math.pi)*self.Std[key][i])) * exp\n",
    "        return prob\n",
    "    def predict(self,data):\n",
    "        result = []\n",
    "        for i in range(data.shape[0]):\n",
    "            MaxProb = 0\n",
    "            MaxProb_key = 0\n",
    "            for key in self.Mean:\n",
    "                Prob_temp = self.probabilty(data[i],key)\n",
    "                if(Prob_temp > MaxProb):\n",
    "                    MaxProb = Prob_temp\n",
    "                    MaxProb_key = key\n",
    "            result.append(MaxProb_key)\n",
    "        return result\n",
    "    def accuracy(self,data,prediction):\n",
    "        correct = 0\n",
    "        for x in range(len(data)):\n",
    "            if data[x] == prediction[x]:\n",
    "                correct += 1\n",
    "        return (correct/float(len(data))) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "89.88603988603988\n"
    }
   ],
   "source": [
    "NB = NaiveBayes()\n",
    "train_labels = np.zeros(train_matrix.shape[0])\n",
    "train_labels[351:701] = 1\n",
    "NB.fit(train_matrix,train_labels)\n",
    "pred = NB.predict(train_matrix)\n",
    "print(NB.accuracy(train_labels,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "80.38461538461539\n"
    }
   ],
   "source": [
    "pred_test = NB.predict(test_matrix)\n",
    "test_label = np.zeros(test_matrix.shape[0])\n",
    "test_label[130:] = 1\n",
    "# print(pred_test)\n",
    "print(NB.accuracy(test_label,pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "98.14814814814815\n95.76923076923077\n"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "GNB = GaussianNB()\n",
    "GNB.fit(train_matrix,train_labels)\n",
    "y_pred = GNB.predict(train_matrix)\n",
    "print(NB.accuracy(train_labels,y_pred))\n",
    "y_pred_test = GNB.predict(test_matrix)\n",
    "print(NB.accuracy(test_label,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}