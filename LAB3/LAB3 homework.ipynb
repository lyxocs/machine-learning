{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.3 64-bit ('base': conda)",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a8f61be024eba58adef938c9aa1e29e02cb3dece83a5348b1a2dafd16a070453"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Dictionary(train_dir):\n",
    "    emails = [os.path.join(train_dir,f) for f in os.listdir(train_dir)]\n",
    "    print(len(emails))\n",
    "    all_words = []\n",
    "    for mail in emails:\n",
    "        with open(mail) as m:\n",
    "            for i,line in enumerate(m):\n",
    "                if i == 2:  #Body of email is only 3rd line of text file\n",
    "                    words = line.split()\n",
    "                    all_words += words\n",
    "    dictionary = Counter(all_words)\n",
    "    dictionary_temp = Counter(all_words)\n",
    "\n",
    "    # Paste code for non-word removal here(code snippet is given below)\n",
    "    list_to_remove = dictionary_temp.keys()\n",
    "    for item in list_to_remove:\n",
    "        if item.isalpha() == False:    #Determine whether it is punctuation\n",
    "            del dictionary[item]\n",
    "        elif len(item) == 1:           #\n",
    "            del dictionary[item]\n",
    "    dictionary = dictionary.most_common(3000)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(root_dir,dictionary):\n",
    "    emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n",
    "    all_words = []\n",
    "    features_matrix = np.zeros((len(emails),3000))\n",
    "    docID = 0\n",
    "    for mail in emails:\n",
    "        with open(mail) as m:\n",
    "            for i,line in enumerate(m):\n",
    "                if i == 2:\n",
    "                    words = line.split()\n",
    "                    for word in words:\n",
    "                        wordID = 0\n",
    "                        for i,d in enumerate(dictionary):\n",
    "                            if d[0] == word:\n",
    "                                wordID = i\n",
    "                                features_matrix[docID,wordID] = words.count(word)\n",
    "            docID = docID + 1\n",
    "    return features_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "702\n[('order', 1414), ('address', 1293), ('report', 1216), ('mail', 1127), ('send', 1079)]\n260\n"
    }
   ],
   "source": [
    "Path = \"train-mails\"\n",
    "dir = make_Dictionary(Path)\n",
    "\n",
    "print(dir[0:5])\n",
    "train_matrix = extract_features(Path,dir)\n",
    "Path_test = \"test-mails\"\n",
    "dir_test = make_Dictionary(Path_test)\n",
    "test_matrix = extract_features(Path_test,dir_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "#Divide the sample\n",
    "    def separate_by_class(self,data):\n",
    "        separated = {}\n",
    "        for i in range(len(data)):\n",
    "            vector = data[i]\n",
    "            if (vector[-1] not in separated):\n",
    "                separated[vector[-1]] = []\n",
    "            separated[vector[-1]].append(vector)\n",
    "        return separated\n",
    "        \n",
    "#Computational features\n",
    "    def mean(self,data):\n",
    "        return sum(data)/float(len(data))\n",
    "    def stdev(self,data):\n",
    "        avg = self.mean(data)\n",
    "        variance = sum([pow(x-avg,2) for x in data])/float(len(data) - 1)\n",
    "        return math.sqrt(variance)\n",
    "    def summarize(self,data):\n",
    "        summaries = [(self.mean(attribute),self.stdev(attribute)) for attribute in zip(*data)]\n",
    "        del summaries[-1]\n",
    "        return summaries\n",
    "\n",
    "#Extract attribute features by category\n",
    "    def summarize_by_class(self,data):\n",
    "        separated = self.separate_by_class(data)\n",
    "        summarizes = {}\n",
    "        keyList = list(separated.keys())\n",
    "        for classValue in keyList:\n",
    "            summarizes[classValue] = self.summarize(separated[classValue])\n",
    "        return summarizes\n",
    "\n",
    "    def calculate_probability(self,x,mean,stdev):\n",
    "        if stdev == 0:\n",
    "            return 0\n",
    "        exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "        return (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent\n",
    "\n",
    "    def calculate_class_probabilities(self,summaries, inputVector):\n",
    "        probabilities = {}\n",
    "        keyList = list(summaries.keys())\n",
    "        for classValue in keyList:\n",
    "            probabilities[classValue] = 1\n",
    "            for i in range(len(summaries[classValue])):\n",
    "                mean,stdev = summaries[classValue][i]\n",
    "                x = inputVector[i]\n",
    "                probabilities[classValue] *= self.calculate_probability(x, mean, stdev)\n",
    "        return probabilities\n",
    "\n",
    "    def predict(self,summaries,inputVector):\n",
    "        probabilities = self.calculate_class_probabilities(summaries,inputVector)\n",
    "        bestLabel, bestProb = None, -1\n",
    "        keyList = list(probabilities.keys())\n",
    "        for classValue in keyList:\n",
    "            if bestLabel is None or probabilities[classValue] > bestProb:\n",
    "                bestProb = probabilities[classValue]\n",
    "                bestLabel = classValue\n",
    "        return bestLabel\n",
    "    def get_prediction(self,summaries, testSet):\n",
    "        predictions = []\n",
    "        for i in range(len(testSet)):\n",
    "            result = self.predict(summaries, testSet[i])\n",
    "            predictions.append(result)\n",
    "        return predictions\n",
    "\n",
    "    def get_accuracy(self,data,predictions):\n",
    "        correct = 0\n",
    "        for x in range(len(data)):\n",
    "            if data[x][-1] == predictions[x]:\n",
    "                correct += 1\n",
    "        return (correct/float(len(data))) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n50.0\n"
    }
   ],
   "source": [
    "train_labels = np.zeros(train_matrix.shape[0])\n",
    "train_labels[351:] = 1\n",
    "# print(train_labels)\n",
    "# print(train_matrix.shape)\n",
    "NB = NaiveBayes()\n",
    "train_labels = train_labels[:,np.newaxis]\n",
    "data_test = np.hstack((train_matrix,train_labels))\n",
    "summaries = NB.summarize_by_class(data_test)\n",
    "predictions = NB.get_prediction(summaries,data_test)\n",
    "print(predictions)\n",
    "accuracy = NB.get_accuracy(data_test,predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "), (0.0, 0.0), (0.008547008547008548, 0.11921599813973957), (0.0, 0.0), (0.014245014245014245, 0.11866850501381614), (0.0, 0.0), (0.011396011396011397, 0.10629360892514285), (0.011396011396011397, 0.10629360892514311), (0.0, 0.0), (0.0, 0.0), (0.014245014245014245, 0.11866850501381618), (0.008547008547008548, 0.09218551132454918), (0.022792022792022793, 0.42700841014689944), (0.019943019943019943, 0.14000406994491132), (0.011396011396011397, 0.1062936089251428), (0.0, 0.0), (0.011396011396011397, 0.13043242316470613), (0.002849002849002849, 0.05337605126836252), (0.022792022792022793, 0.1986933302328976), (0.02564102564102564, 0.2867015908532811), (0.005698005698005698, 0.07537722256574367), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.02849002849002849, 0.16660560542018937), (0.019943019943019943, 0.14000406994491138), (0.0, 0.0), (0.02564102564102564, 0.20542103640523895), (0.02849002849002849, 0.2710566609986067), (0.019943019943019943, 0.21948250083450327), (0.005698005698005698, 0.07537722256574365), (0.019943019943019943, 0.24413344629759148), (0.008547008547008548, 0.11921599813973938), (0.02564102564102564, 0.1582875391651063), (0.02849002849002849, 0.1829527629518438), (0.0, 0.0), (0.02849002849002849, 0.1666056054201894), (0.02849002849002849, 0.19795453817985387), (0.019943019943019943, 0.1400040699449114), (0.02564102564102564, 0.1582875391651062), (0.0, 0.0), (0.02564102564102564, 0.17541160386140572), (0.02564102564102564, 0.33282011773513837), (0.02564102564102564, 0.1582875391651063), (0.02564102564102564, 0.19100658753958508), (0.0, 0.0), (0.02849002849002849, 0.19795453817985392), (0.0, 0.0), (0.03133903133903134, 0.286133189043499), (0.03133903133903134, 0.34081947737463153), (0.03133903133903134, 0.3408194773746316), (0.03133903133903134, 0.17448103175884408), (0.03133903133903134, 0.17448103175884322), (0.03133903133903134, 0.17448103175884322), (0.03133903133903134, 0.1901523498616742), (0.03133903133903134, 0.2046269822682298), (0.03133903133903134, 0.21814327307182269), (0.03133903133903134, 0.48596081751301284), (0.03133903133903134, 0.17448103175884358), (0.03133903133903134, 0.275967237471981), (0.03133903133903134, 0.44289718463534233), (0.03133903133903134, 0.34910199350935045), (0.03133903133903134, 0.17448103175884327), (0.03133903133903134, 0.21814327307182263), (0.03133903133903134, 0.17448103175884372), (0.03133903133903134, 0.23086960237496365), (0.03133903133903134, 0.3804331015163439), (0.03133903133903134, 0.34910199350934995), (0.03133903133903134, 0.5871365639519859), (0.0, 0.0), (0.0, 0.0), (0.011396011396011397, 0.21350420507345091), (0.008547008547008548, 0.09218551132454855), (0.005698005698005698, 0.10675210253672554), (0.011396011396011397, 0.13043242316470585), (0.005698005698005698, 0.07537722256574375), (0.017094017094017096, 0.19926605257032556), (0.014245014245014245, 0.11866850501381616), (0.017094017094017096, 0.23843199627947873), (0.0, 0.0), (0.017094017094017096, 0.1298068443874083), (0.002849002849002849, 0.05337605126836255), (0.008547008547008548, 0.09218551132454882), (0.017094017094017096, 0.16816179196948525), (0.002849002849002849, 0.053376051268362416), (0.002849002849002849, 0.05337605126836258), (0.008547008547008548, 0.11921599813973921), (0.0, 0.0), (0.0, 0.0), (0.011396011396011397, 0.10629360892514293), (0.0, 0.0), (0.005698005698005698, 0.07537722256574365), (0.002849002849002849, 0.05337605126836269), (0.0, 0.0), (0.002849002849002849, 0.0533760512683625), (0.005698005698005698, 0.07537722256574372), (0.02564102564102564, 0.21888830008040144), (0.014245014245014245, 0.1186685050138161), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.005698005698005698, 0.07537722256574368), (0.0, 0.0), (0.005698005698005698, 0.07537722256574364), (0.0, 0.0), (0.005698005698005698, 0.07537722256574357), (0.019943019943019943, 0.32452338176998136), (0.019943019943019943, 0.14000406994491169), (0.002849002849002849, 0.05337605126836263), (0.0, 0.0), (0.008547008547008548, 0.092185511324549), (0.008547008547008548, 0.09218551132454905), (0.005698005698005698, 0.07537722256574365), (0.005698005698005698, 0.07537722256574371), (0.014245014245014245, 0.2668802563418119), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.011396011396011397, 0.10629360892514288), (0.0, 0.0), (0.019943019943019943, 0.14000406994491105), (0.008547008547008548, 0.09218551132454865), (0.002849002849002849, 0.05337605126836243), (0.005698005698005698, 0.07537722256574358), (0.011396011396011397, 0.15075444513148753), (0.005698005698005698, 0.07537722256574365), (0.017094017094017096, 0.1298068443874082), (0.011396011396011397, 0.10629360892514335), (0.0, 0.0), (0.0, 0.0), (0.02564102564102564, 0.2765565339736476), (0.0, 0.0), (0.022792022792022793, 0.3287103102284281), (0.002849002849002849, 0.05337605126836267), (0.014245014245014245, 0.1407000348134279), (0.011396011396011397, 0.13043242316470582), (0.011396011396011397, 0.10629360892514285), (0.022792022792022793, 0.19869333023289718), (0.0, 0.0), (0.002849002849002849, 0.053376051268362784), (0.0, 0.0), (0.022792022792022793, 0.1494529435514149), (0.0, 0.0), (0.008547008547008548, 0.09218551132454965), (0.019943019943019943, 0.14000406994491132), (0.017094017094017096, 0.15021352323976175), (0.02564102564102564, 0.15828753916510613), (0.011396011396011397, 0.15075444513148756), (0.0, 0.0), (0.02564102564102564, 0.1754116038614068), (0.022792022792022793, 0.14945294355141486), (0.005698005698005698, 0.07537722256574372), (0.002849002849002849, 0.05337605126836264), (0.0, 0.0), (0.011396011396011397, 0.10629360892514308), (0.0, 0.0), (0.0, 0.0), (0.02564102564102564, 0.1582875391651063), (0.0, 0.0), (0.005698005698005698, 0.10675210253672554), (0.011396011396011397, 0.15075444513148753), (0.005698005698005698, 0.07537722256574363), (0.0, 0.0), (0.005698005698005698, 0.10675210253672515), (0.022792022792022793, 0.1494529435514146), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.005698005698005698, 0.07537722256574372), (0.014245014245014245, 0.2199270978481924), (0.008547008547008548, 0.16012815380508555), (0.017094017094017096, 0.12980684438740792), (0.022792022792022793, 0.19869333023289654), (0.008547008547008548, 0.16012815380508555), (0.022792022792022793, 0.1986933302328967), (0.014245014245014245, 0.19219614184305825), (0.0, 0.0), (0.008547008547008548, 0.09218551132454965), (0.022792022792022793, 0.32871031022842906), (0.005698005698005698, 0.10675210253672512), (0.022792022792022793, 0.14945294355141486), (0.019943019943019943, 0.15910821888081417), (0.019943019943019943, 0.23213542143941263), (0.014245014245014245, 0.11866850501381614), (0.022792022792022793, 0.14945294355141486), (0.0, 0.0), (0.017094017094017096, 0.12980684438740836), (0.02564102564102564, 0.3882901373576609), (0.02564102564102564, 0.15828753916510627), (0.011396011396011397, 0.16864515540385008), (0.011396011396011397, 0.10629360892514292), (0.0, 0.0), (0.02564102564102564, 0.3808607948515377), (0.02564102564102564, 0.21888830008040222), (0.019943019943019943, 0.1916872367790725), (0.02564102564102564, 0.17541160386140656), (0.02564102564102564, 0.20542103640523982), (0.02849002849002849, 0.2710566609986067), (0.02849002849002849, 0.16660560542018926), (0.02849002849002849, 0.16660560542018943), (0.02849002849002849, 0.1829527629518439), (0.02849002849002849, 0.29137653457388263), (0.02849002849002849, 0.24908460820199652), (0.02849002849002849, 0.16660560542018932), (0.02849002849002849, 0.16660560542018937), (0.02849002849002849, 0.16660560542018937), (0.02849002849002849, 0.1979545381798541), (0.02849002849002849, 0.16660560542018935), (0.02849002849002849, 0.21189687326689136), (0.02849002849002849, 0.16660560542018932), (0.02849002849002849, 0.37688611282871937), (0.02849002849002849, 0.34523325330274784), (0.02849002849002849, 0.18295276295184387), (0.02849002849002849, 0.1666056054201894), (0.02849002849002849, 0.16660560542018932), (0.02849002849002849, 0.2814000696268556), (0.02849002849002849, 0.4333098519044171), (0.02849002849002849, 0.2814000696268557), (0.02849002849002849, 0.1666056054201894), (0.02849002849002849, 0.16660560542018935), (0.02849002849002849, 0.2249768223941538), (0.02849002849002849, 0.21189687326689124), (0.02849002849002849, 0.2490846082019966), (0.02849002849002849, 0.16660560542018937), (0.02849002849002849, 0.48318910736037246), (0.02849002849002849, 0.224976822394154), (0.02849002849002849, 0.3282642651240428), (0.02849002849002849, 0.3452332533027478), (0.02849002849002849, 0.3103689036112613), (0.02849002849002849, 0.18295276295184373), (0.02849002849002849, 0.2710566609986066), (0.02849002849002849, 0.5337605126836238), (0.02849002849002849, 0.31036890361126124), (0.02849002849002849, 0.4060791608791135), (0.02849002849002849, 0.40607916087911344), (0.0, 0.0), (0.0, 0.0), (0.002849002849002849, 0.05337605126836258), (0.002849002849002849, 0.05337605126836277), (0.0, 0.0), (0.011396011396011397, 0.10629360892514311), (0.002849002849002849, 0.053376051268362396), (0.014245014245014245, 0.11866850501381611), (0.0, 0.0), (0.0, 0.0), (0.005698005698005698, 0.07537722256574368), (0.002849002849002849, 0.05337605126836258), (0.0, 0.0), (0.005698005698005698, 0.10675210253672535), (0.002849002849002849, 0.05337605126836247), (0.022792022792022793, 0.14945294355141478), (0.0, 0.0), (0.011396011396011397, 0.10629360892514314), (0.0, 0.0), (0.002849002849002849, 0.05337605126836245), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.008547008547008548, 0.09218551132454894), (0.0, 0.0), (0.002849002849002849, 0.05337605126836267), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.002849002849002849, 0.05337605126836252), (0.011396011396011397, 0.13043242316470582), (0.0, 0.0), (0.0, 0.0), (0.002849002849002849, 0.05337605126836247), (0.002849002849002849, 0.05337605126836258), (0.0, 0.0), (0.008547008547008548, 0.1192159981397394), (0.005698005698005698, 0.07537722256574363), (0.011396011396011397, 0.10629360892514302), (0.002849002849002849, 0.05337605126836279), (0.002849002849002849, 0.05337605126836247), (0.002849002849002849, 0.05337605126836275), (0.014245014245014245, 0.17670617200616182), (0.002849002849002849, 0.053376051268362576), (0.0, 0.0), (0.017094017094017096, 0.27201594437215304), (0.014245014245014245, 0.11866850501381614), (0.0, 0.0), (0.022792022792022793, 0.2918789564071462), (0.002849002849002849, 0.053376051268362416), (0.005698005698005698, 0.07537722256574372), (0.0, 0.0), (0.008547008547008548, 0.09218551132454858), (0.0, 0.0), (0.014245014245014245, 0.11866850501381614), (0.0, 0.0), (0.002849002849002849, 0.05337605126836258), (0.019943019943019943, 0.1591082188808144), (0.022792022792022793, 0.14945294355141453), (0.017094017094017096, 0.16816179196948508), (0.008547008547008548, 0.09218551132454873), (0.0, 0.0), (0.002849002849002849, 0.05337605126836277), (0.011396011396011397, 0.13043242316470588), (0.0, 0.0), (0.002849002849002849, 0.053376051268362694), (0.002849002849002849, 0.053376051268362784), (0.0, 0.0), (0.005698005698005698, 0.07537722256574364), (0.005698005698005698, 0.07537722256574372), (0.0, 0.0), (0.0, 0.0), (0.014245014245014245, 0.11866850501381616), (0.017094017094017096, 0.12980684438740814), (0.011396011396011397, 0.10629360892514311), (0.022792022792022793, 0.14945294355141486), (0.0, 0.0), (0.005698005698005698, 0.10675210253672539), (0.019943019943019943, 0.14000406994491135), (0.022792022792022793, 0.1986933302328978), (0.0, 0.0), (0.005698005698005698, 0.0753772225657438), (0.005698005698005698, 0.07537722256574364), (0.002849002849002849, 0.0533760512683627), (0.0, 0.0), (0.022792022792022793, 0.23795355980084912), (0.0, 0.0), (0.005698005698005698, 0.07537722256574371), (0.0, 0.0), (0.005698005698005698, 0.10675210253672517), (0.017094017094017096, 0.32025630761017404), (0.011396011396011397, 0.10629360892514285), (0.014245014245014245, 0.15972096140076775), (0.008547008547008548, 0.09218551132454897), (0.0, 0.0), (0.022792022792022793, 0.28192027149362514), (0.0, 0.0), (0.008547008547008548, 0.0921855113245487), (0.0, 0.0), (0.002849002849002849, 0.053376051268362604), (0.0, 0.0), (0.002849002849002849, 0.053376051268362514), (0.019943019943019943, 0.2770270686124303), (0.017094017094017096, 0.12980684438740805), (0.0, 0.0), (0.019943019943019943, 0.19168723677907323), (0.0, 0.0), (0.002849002849002849, 0.0533760512683626), (0.017094017094017096, 0.18437102264909852), (0.0, 0.0), (0.008547008547008548, 0.09218551132454876), (0.017094017094017096, 0.16816179196948583), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.019943019943019943, 0.14000406994491174), (0.0, 0.0), (0.019943019943019943, 0.14000406994491132), (0.011396011396011397, 0.10629360892514336), (0.0, 0.0), (0.022792022792022793, 0.14945294355141475), (0.011396011396011397, 0.2135042050734502), (0.022792022792022793, 0.16748273955983572), (0.014245014245014245, 0.14070003481342783), (0.002849002849002849, 0.0533760512683627), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.017094017094017096, 0.12980684438740817), (0.019943019943019943, 0.14000406994491132), (0.019943019943019943, 0.14000406994491132), (0.005698005698005698, 0.07537722256574358), (0.0, 0.0), (0.022792022792022793, 0.14945294355141472), (0.014245014245014245, 0.11866850501381616), (0.019943019943019943, 0.23213542143941263), (0.017094017094017096, 0.22613166769723198), (0.0, 0.0), (0.022792022792022793, 0.1837518809828993), (0.0, 0.0), (0.014245014245014245, 0.11866850501381616), (0.002849002849002849, 0.05337605126836252), (0.019943019943019943, 0.14000406994491107), (0.022792022792022793, 0.1494529435514146), (0.022792022792022793, 0.21258721785028567), (0.019943019943019943, 0.14000406994491132), (0.0, 0.0), (0.022792022792022793, 0.14945294355141475), (0.0, 0.0), (0.0, 0.0), (0.022792022792022793, 0.23795355980084923), (0.019943019943019943, 0.14000406994491132), (0.0, 0.0), (0.022792022792022793, 0.14945294355141509), (0.0, 0.0), (0.022792022792022793, 0.16748273955983667), (0.0, 0.0), (0.005698005698005698, 0.07537722256574367), (0.02564102564102564, 0.15828753916510616), (0.02564102564102564, 0.19100658753958422), (0.02564102564102564, 0.2765565339736476), (0.02564102564102564, 0.2765565339736476), (0.02564102564102564, 0.1582875391651063), (0.02564102564102564, 0.17541160386140667), (0.02564102564102564, 0.158287539165107), (0.02564102564102564, 0.1582875391651064), (0.02564102564102564, 0.4803844614152551), (0.02564102564102564, 0.17541160386140642), (0.02564102564102564, 0.1582875391651062), (0.02564102564102564, 0.1582875391651065), (0.02564102564102564, 0.1754116038614063), (0.02564102564102564, 0.20542103640523954), (0.02564102564102564, 0.21888830008040283), (0.02564102564102564, 0.1582875391651067), (0.02564102564102564, 0.30598427022704017), (0.02564102564102564, 0.15828753916510632), (0.02564102564102564, 0.1910065875395845), (0.02564102564102564, 0.15828753916510618), (0.02564102564102564, 0.15828753916510643), (0.02564102564102564, 0.1582875391651063), (0.02564102564102564, 0.15828753916510643), (0.02564102564102564, 0.1582875391651063), (0.02564102564102564, 0.15828753916510624), (0.02564102564102564, 0.15828753916510624), (0.02564102564102564, 0.15828753916510616), (0.02564102564102564, 0.15828753916510643), (0.02564102564102564, 0.21888830008040283), (0.02564102564102564, 0.2435993828823455), (0.02564102564102564, 0.4301801309392887), (0.02564102564102564, 0.24359938288234564), (0.02564102564102564, 0.21888830008040153), (0.02564102564102564, 0.1582875391651063), (0.02564102564102564, 0.48038446141526076), (0.02564102564102564, 0.2765565339736462), (0.0, 0.0), (0.0, 0.0), (0.008547008547008548, 0.09218551132454898), (0.0, 0.0), (0.011396011396011397, 0.13043242316470632), (0.0, 0.0), (0.008547008547008548, 0.11921599813973915), (0.0, 0.0), (0.0, 0.0), (0.019943019943019943, 0.1400040699449115), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.002849002849002849, 0.053376051268362715), (0.008547008547008548, 0.09218551132454919), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.002849002849002849, 0.05337605126836264), (0.008547008547008548, 0.09218551132454898), (0.019943019943019943, 0.1400040699449114), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.017094017094017096, 0.12980684438740822), (0.0, 0.0), (0.005698005698005698, 0.07537722256574374), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.002849002849002849, 0.05337605126836264), (0.019943019943019943, 0.17615252206457552), (0.014245014245014245, 0.11866850501381615), (0.0, 0.0), (0.005698005698005698, 0.07537722256574364), (0.0, 0.0), (0.008547008547008548, 0.09218551132454876), (0.002849002849002849, 0.053376051268362784), (0.0, 0.0), (0.005698005698005698, 0.07537722256574377), (0.0, 0.0), (0.008547008547008548, 0.09218551132454883), (0.0, 0.0), (0.019943019943019943, 0.14000406994491107), (0.005698005698005698, 0.10675210253672544), (0.002849002849002849, 0.05337605126836263), (0.002849002849002849, 0.053376051268362784), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.017094017094017096, 0.12980684438740817), (0.011396011396011397, 0.10629360892514335), (0.005698005698005698, 0.07537722256574358), (0.017094017094017096, 0.12980684438740794), (0.0, 0.0), (0.005698005698005698, 0.07537722256574358), (0.008547008547008548, 0.11921599813973931), (0.014245014245014245, 0.14070003481342788), (0.008547008547008548, 0.09218551132454879), (0.005698005698005698, 0.07537722256574358), (0.011396011396011397, 0.1507544451314872), (0.0, 0.0), (0.002849002849002849, 0.05337605126836256), (0.002849002849002849, 0.053376051268362666), (0.0, 0.0), (0.0, 0.0), (0.011396011396011397, 0.13043242316470638), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.017094017094017096, 0.12980684438740803), (0.0, 0.0), (0.002849002849002849, 0.05337605126836258), (0.017094017094017096, 0.1502135232397619), (0.014245014245014245, 0.11866850501381616), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.014245014245014245, 0.2199270978481924), (0.0, 0.0), (0.0, 0.0), (0.005698005698005698, 0.0753772225657436), (0.005698005698005698, 0.07537722256574363), (0.002849002849002849, 0.05337605126836244), (0.002849002849002849, 0.05337605126836247), (0.0, 0.0), (0.011396011396011397, 0.21350420507345078), (0.005698005698005698, 0.07537722256574361), (0.002849002849002849, 0.053376051268362715), (0.014245014245014245, 0.11866850501381615), (0.014245014245014245, 0.15972096140076775), (0.0, 0.0), (0.002849002849002849, 0.05337605126836264), (0.014245014245014245, 0.1186685050138161), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.011396011396011397, 0.10629360892514311), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.017094017094017096, 0.15021352323976175), (0.019943019943019943, 0.14000406994491146), (0.008547008547008548, 0.09218551132454893), (0.0, 0.0), (0.002849002849002849, 0.05337605126836264), (0.0, 0.0), (0.008547008547008548, 0.11921599813973914), (0.0, 0.0), (0.002849002849002849, 0.05337605126836258), (0.017094017094017096, 0.1298068443874083), (0.002849002849002849, 0.05337605126836247), (0.019943019943019943, 0.1400040699449118), (0.008547008547008548, 0.11921599813973908), (0.0, 0.0), (0.0, 0.0), (0.019943019943019943, 0.19168723677907235), (0.011396011396011397, 0.10629360892514306), (0.008547008547008548, 0.09218551132454891), (0.011396011396011397, 0.13043242316470596), (0.002849002849002849, 0.053376051268362576), (0.005698005698005698, 0.07537722256574364), (0.008547008547008548, 0.09218551132454894), (0.002849002849002849, 0.0533760512683627), (0.005698005698005698, 0.10675210253672535), (0.019943019943019943, 0.1400040699449113), (0.011396011396011397, 0.10629360892514286), (0.011396011396011397, 0.10629360892514306), (0.0, 0.0), (0.0, 0.0), (0.005698005698005698, 0.10675210253672483), (0.002849002849002849, 0.05337605126836245), (0.0, 0.0), (0.0, 0.0), (0.002849002849002849, 0.05337605126836269), (0.0, 0.0), (0.017094017094017096, 0.12980684438740792), (0.019943019943019943, 0.23213542143941215), (0.017094017094017096, 0.12980684438740822)]}\n"
    }
   ],
   "source": [
    "print(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "dict_keys([0.0, 1.0])\n"
    }
   ],
   "source": [
    "separated = NB.separate_by_class(data_test)\n",
    "print(separated.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}